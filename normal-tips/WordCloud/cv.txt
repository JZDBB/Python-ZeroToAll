为什么要学习计算机视觉？


一个显而易见的答案就是，这个研究领域已经衍生出了一大批快速成长的、有实际作用的应用，例如：
人脸识别： Snapchat 和 Facebook 使用人脸检测算法来识别人脸。
图像检索：Google Images 使用基于内容的查询来搜索相关图片，算法分析查询图像中的内容并根据最佳匹配内容返回结果。
游戏和控制：使用立体视觉较为成功的游戏应用产品是：微软 Kinect。
监测：用于监测可疑行为的监视摄像头遍布于各大公共场所中。
生物识别技术：指纹、虹膜和人脸匹配仍然是生物识别领域的一些常用方法。
智能汽车：计算机视觉仍然是检测交通标志、灯光和其他视觉特征的主要信息来源。
视觉识别是计算机视觉的关键组成部分，如图像分类、定位和检测。神经网络和深度学习的最新进展极大地推动了这些最先进的视觉识别系统的发展。在本文中，我将分享 5 种主要的计算机视觉技术，并介绍几种基于计算机视觉技术的深度学习模型与应用。
图像分类
视点变化，尺度变化，类内变化，图像变形，图像遮挡，照明条件和背景杂斑

工智能是人类一个非常美好的梦想，跟星际漫游和长生不老一样。我们想制造出一种机器，使得它跟人一样具有一定的对外界事物感知能力，比如看见世界。

在上世纪50年代，数学家图灵提出判断机器是否具有人工智能的标准：图灵测试。即把机器放在一个房间，人类测试员在另一个房间，人跟机器聊天，测试员事先不知道另一房间里是人还是机器 。经过聊天，如果测试员不能确定跟他聊天的是人还是机器的话，那么图灵测试就通过了，也就是说这个机器具有与人一样的感知能力。

但是从图灵测试提出来开始到本世纪初，50多年时间有无数科学家提出很多机器学习的算法，试图让计算机具有与人一样的智力水平，但直到2006年深度学习算法的成功，才带来了一丝解决的希望。

众星捧月的深度学习
深度学习在很多学术领域，比非深度学习算法往往有20-30%成绩的提高。很多大公司也逐渐开始出手投资这种算法，并成立自己的深度学习团队，其中投入最大的就是谷歌，2008年6月披露了谷歌脑项目。2014年1月谷歌收购DeepMind，然后2016年3月其开发的Alphago算法在围棋挑战赛中，战胜了韩国九段棋手李世石，证明深度学习设计出的算法可以战胜这个世界上最强的选手。

在硬件方面，Nvidia最开始做显示芯片，但从2006及2007年开始主推用GPU芯片进行通用计算，它特别适合深度学习中大量简单重复的计算量。目前很多人选择Nvidia的CUDA工具包进行深度学习软件的开发。

微软从2012年开始，利用深度学习进行机器翻译和中文语音合成工作，其人工智能小娜背后就是一套自然语言处理和语音识别的数据算法。

百度在2013年宣布成立百度研究院，其中最重要的就是百度深度学习研究所，当时招募了著名科学家余凯博士。不过后来余凯离开百度，创立了另一家从事深度学习算法开发的公司地平线。

Facebook和Twitter也都各自进行了深度学习研究，其中前者携手纽约大学教授Yann Lecun，建立了自己的深度学习算法实验室；2015年10月，Facebook宣布开源其深度学习算法框架，即Torch框架。Twitter在2014年7月收购了Madbits，为用户提供高精度的图像检索服务。

前深度学习时代的计算机视觉
互联网巨头看重深度学习当然不是为了学术，主要是它能带来巨大的市场。那为什么在深度学习出来之前，传统算法为什么没有达到深度学习的精度？

在深度学习算法出来之前，对于视觉算法来说，大致可以分为以下5个步骤：特征感知，图像预处理，特征提取，特征筛选，推理预测与识别。早期的机器学习中，占优势的统计机器学习群体中，对特征是不大关心的。

我认为，计算机视觉可以说是机器学习在视觉领域的应用，所以计算机视觉在采用这些机器学习方法的时候，不得不自己设计前面4个部分。

但对任何人来说这都是一个比较难的任务。传统的计算机识别方法把特征提取和分类器设计分开来做，然后在应用时再合在一起，比如如果输入是一个摩托车图像的话，首先要有一个特征表达或者特征提取的过程，然后把表达出来的特征放到学习算法中进行分类的学习。

过去20年中出现了不少优秀的特征算子，比如最著名的SIFT算子，即所谓的对尺度旋转保持不变的算子。它被广泛地应用在图像比对，特别是所谓的structure from motion这些应用中，有一些成功的应用例子。另一个是HoG算子，它可以提取物体，比较鲁棒的物体边缘，在物体检测中扮演着重要的角色。

这些算子还包括Textons，Spin image，RIFT和GLOH，都是在深度学习诞生之前或者深度学习真正的流行起来之前，占领视觉算法的主流。

几个（半）成功例子
这些特征和一些特定的分类器组合取得了一些成功或半成功的例子，基本达到了商业化的要求但还没有完全商业化。

一是八九十年代的指纹识别算法，它已经非常成熟，一般是在指纹的图案上面去寻找一些关键点，寻找具有特殊几何特征的点，然后把两个指纹的关键点进行比对，判断是否匹配。

然后是2001年基于Haar的人脸检测算法，在当时的硬件条件下已经能够达到实时人脸检测，我们现在所有手机相机里的人脸检测，都是基于它或者它的变种。

第三个是基于HoG特征的物体检测，它和所对应的SVM分类器组合起来的就是著名的DPM算法。DPM算法在物体检测上超过了所有的算法，取得了比较不错的成绩。

但这种成功例子太少了，因为手工设计特征需要大量的经验，需要你对这个领域和数据特别了解，然后设计出来特征还需要大量的调试工作。说白了就是需要一点运气。

另一个难点在于，你不只需要手工设计特征，还要在此基础上有一个比较合适的分类器算法。同时设计特征然后选择一个分类器，这两者合并达到最优的效果，几乎是不可能完成的任务。

仿生学角度看深度学习
如果不手动设计特征，不挑选分类器，有没有别的方案呢？能不能同时学习特征和分类器？即输入某一个模型的时候，输入只是图片，输出就是它自己的标签。比如输入一个明星的头像，出来的标签就是一个50维的向量（如果要在50个人里识别的话），其中对应明星的向量是1，其他的位置是0。

模拟人脑识别人脸，也是抽象迭代的过程，从最开始的像素到第二层的边缘，再到人脸的部分，然后到整张人脸，是一个抽象迭代的过程。

再比如看到图片中的摩托车，我们可能在脑子里就几微秒的时间，但是经过了大量的神经元抽象迭代。对计算机来说最开始看到的根本也不是摩托车，而是RGB图像三个通道上不同的数字。

所谓的特征或者视觉特征，就是把这些数值给综合起来用统计或非统计的形式，把摩托车的部件或者整辆摩托车表现出来。深度学习的流行之前，大部分的设计图像特征就是基于此，即把一个区域内的像素级别的信息综合表现出来，利于后面的分类学习。

如果要完全模拟人脑，我们也要模拟抽象和递归迭代的过程，把信息从最细琐的像素级别，抽象到“种类”的概念，让人能够接受。

卷积的概念
计算机视觉里经常使卷积神经网络，即CNN，是一种对人脑比较精准的模拟。

什么是卷积？卷积就是两个函数之间的相互关系，然后得出一个新的值，他是在连续空间做积分计算，然后在离散空间内求和的过程。实际上在计算机视觉里面，可以把卷积当做一个抽象的过程，就是把小区域内的信息统计抽象出来。

比如，对于一张爱因斯坦的照片，我可以学习n个不同的卷积和函数，然后对这个区域进行统计。可以用不同的方法统计，比如着重统计中央，也可以着重统计周围，这就导致统计的和函数的种类多种多样，为了达到可以同时学习多个统计的累积和。

计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取‘信息’的人工智能系统。这里所 指的信息指Shannon定义的，可以用来帮助做一个“决定”的信息。因为感知可以看作是从感官信号中提 取信息，所以计算机视觉也可以看作是研究如何使人工系统从图像或多维数据中“感知”的科学。

视觉是各个应用领域，如制造业、检验、文档分析、医疗诊断，和军事等领域中各种智能/自主系统中不可分割的一部分。由于它的重要性，一些先进国家，例如美国把对计算机视觉的
计算机视觉与其他领域的关系
研究列为对经济和科学有广泛影响的科学和工程中的重大基本问题，即所谓的重大挑战（grand challenge）。计算机视觉的挑战是要为计算机和机器人开发具有与人类水平相当的视觉能力。机器视觉需要图象信号，纹理和颜色建模，几何处理和推理，以及物体建模。一个有能力的视觉系统应该把所有这些处理都紧密地集成在一起。作为一门学科，计算机视觉开始于60年代初，但在计算机视觉的基本研究中的许多重要进展是在80年代取得的。计算机视觉与人类视觉密切相关，对人类视觉有一个正确的认识将对计算机视觉的研究非常有益。为此我们将先介绍人类视觉。

计算机视觉领域的突出特点是其多样性与不完善性。这一领域的先驱可追溯到更早的时候，但是直到20世纪70年代后期，当计算机的性能提高到足以处理诸如图像这样的大规模数据时，计算机视觉才得到了正式的关注和发展。然而这些发展往往起源于其他不同领域的需要，因而何谓“计算机视觉问题”始终没有得到正式定义，很自然地，“计算机视觉问题”应当被如何解决也没有成型的公式。
尽管如此，人们已开始掌握部分解决具体计算机视觉任务的方法，可惜这些方法通常都仅适用于一群狭隘的目标（如：脸孔、指纹、文字等），因而无法被广泛地应用于不同场合。
对这些方法的应用通常作为某些解决复杂问题的大规模系统的一个组成部分（例如医学图像的处理，工业制造中的质量控制与测量）。在计算机视觉的大多数实际应用当中，计算机被预设为解决特定的任务，然而基于机器学习的方法正日渐普及，一旦机器学习的研究进一步发展，未来“泛用型”的电脑视觉应用或许可以成真。
人工智能所研究的一个主要问题是：如何让系统具备“计划”和“决策能力”？从而使之完成特定的技术动作（例如：移动一个机器人通过某种特定环境）。这一问题便与计算机视觉问题息息相关。在这里，计算机视觉系统作为一个感知器，为决策提供信息。另外一些研究方向包括模式识别和机器学习（这也隶属于人工智能领域，但与计算机视觉有着重要联系），也由此，计算机视觉时常被看作人工智能与计算机科学的一个分支。
物理是与计算机视觉有着重要联系的另一领域。
计算机视觉关注的目标在于充分理解电磁波——主要是可见光与红外线部分——遇到物体表面被反射所形成的图像，而这一过程便是基于光学物理和固态物理，一些尖端的图像感知系统甚至会应用到量子力学理论，来解析影像所表示的真实世界。同时，物理学中的很多测量难题也可以通过计算机视觉得到解决，例如流体运动。也由此，计算机视觉同样可以被看作是物理学的拓展。
另一个具有重要意义的领域是神经生物学，尤其是其中生物视觉系统的部分。
在整个20世纪中，人类对各种动物的眼睛、神经元、以及与视觉刺激相关的脑部组织都进行了广泛研究，这些研究得出了一些有关“天然的”视觉系统如何运作的描述（尽管仍略嫌粗略），这也形成了计算机视觉中的一个子领域——人们试图建立人工系统，使之在不同的复杂程度上模拟生物的视觉运作。同时计算机视觉领域中，一些基于机器学习的方法也有参考部分生物机制。
计算机视觉的另一个相关领域是信号处理。很多有关单元变量信号的处理方法，尤其是对时变信号的处理，都可以很自然的被扩展为计算机视觉中对二元变量信号或者多元变量信号的处理方法。但由于图像数据的特有属性，很多计算机视觉中发展起来的方法，在单元信号的处理方法中却找不到对应版本。这类方法的一个主要特征，便是他们的非线性以及图像信息的多维性，以上二点作为计算机视觉的一部分，在信号处理学中形成了一个特殊的研究方向。
除了上面提到的领域，很多研究课题同样可被当作纯粹的数学问题。例如，计算机视觉中的很多问题，其理论基础便是统计学，最优化理论以及几何学。
如何使既有方法通过各种软硬件实现，或说如何对这些方法加以修改，而使之获得合理的执行速度而又不损失足够精度，是现今电脑视觉领域的主要课题。

人类正在进入信息时代，计算机将越来越广泛地进入几乎所有领域。一方面是更多未经计算机专业训练的人也需要应用计算机，而另一方面是计算机的功能越来越强，使用方法越来越复杂。这就使人在进行交谈和通讯时的灵活性与在使用计算机时所要求的严格和死板之间产生了尖锐的矛盾。人可通过视觉和听觉，语言与外界交换信息，并且可用不同的方式表示相同的含义，而计算机却要求严格按照各种程序语言来编写程序，只有这样计算机才能运行。为使更多的人能使用复杂的计算机，必须改变过去的那种让人来适应计算机，来死记硬背计算机的使用规则的情况。而是反过来让计算机来适应人的习惯和要求，以人所习惯的方式与人进行信息交换，也就是让计算机具有视觉、听觉和说话等能力。这时计算机必须具有逻辑推理和决策的能力。具有上述能力的计算机就是智能计算机。
智能计算机不但使计算机更便于为人们所使用，同时如果用这样的计算机来控制各种自动化装置特别是智能机器人，就可以使这些自动化系统和智能机器人具有适应环境，和自主作出决策的能力。这就可以在各种场合取代人的繁重工作，或代替人到各种危险和恶劣环境中完成任务。
应用范围从任务，比如工业机器视觉系统，比方说，检查瓶子上的生产线加速通过，研究为人工智能和计算机或机器人，可以理解他们周围的世界。计算机视觉和机器视觉领域有显著的重叠。计算机视觉涉及的被用于许多领域自动化图像分析的核心技术。机器视觉通常指的是结合自动图像分析与其他方法和技术，以提供自动检测和机器人指导在工业应用中的一个过程。在许多计算机视觉应用中，计算机被预编程，以解决特定的任务，但基于学习的方法现在正变得越来越普遍。计算机视觉应用的实例包括用于系统：
